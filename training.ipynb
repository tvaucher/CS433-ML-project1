{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### THIS FIRST PART SHOULD BE IN TRAIN.PY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from preprocessing import load_csv_data, preprocessing_pipeline, split_data_by_categorical_column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from implementations import reg_logistic_regression, svm, ridge_regression\n",
    "from helpers import predict_labels, compute_accuracy\n",
    "from cross_validation import k_fold_indices, k_fold_cross_split_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRI_JET_NUM_INDEX = 22\n",
    "SEED = 2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_classes, train_data, train_ids = load_csv_data(\"data/train.csv\")\n",
    "train_classes_jet_num_splits, train_data_jet_num_splits, train_ids_jet_num_splits = \\\n",
    "    split_data_by_categorical_column(train_classes,\n",
    "                                     train_data,\n",
    "                                     train_ids,\n",
    "                                     PRI_JET_NUM_INDEX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "POSSIBLE_LAMBDA_VALUES = [1e-6, 5e-5, 2.5e-5, 1e-5, 7.5e-4, 5e-4, 2.5e-4, 1e-4, 0]\n",
    "POSSIBLE_LAMBDA_LOG = [0]\n",
    "POSSIBLE_LAMBDA_SVM = [1e-2]\n",
    "POSSIBLE_DEGREES = np.arange(5, 14)\n",
    "grid_shape = (4, 1, len(POSSIBLE_DEGREES), len(POSSIBLE_LAMBDA_VALUES), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm_notebook as tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_accuracy_matrix = np.zeros(grid_shape)\n",
    "validation_accuracy_matrix = np.zeros(grid_shape)\n",
    "\n",
    "for jet_num, (train_classes_split, train_data_split) in enumerate(tqdm(zip(train_classes_jet_num_splits, train_data_jet_num_splits), total=4, desc='PRI_JET_NUM')):\n",
    "    k_indices = k_fold_indices(train_data_split.shape[0], 5, SEED)\n",
    "    for i, deg in enumerate(tqdm(POSSIBLE_DEGREES, desc='deg loop', leave=False)):\n",
    "        train_data, _ = preprocessing_pipeline(train_data_split, degree=deg)\n",
    "        train_set_folds = k_fold_cross_split_data(train_classes_split, train_data, k_indices)\n",
    "     \n",
    "        ### Train Ridge model on fold\n",
    "        for j, lambda_ in enumerate(tqdm(POSSIBLE_LAMBDA_VALUES, desc='lambda loop', leave=False)):\n",
    "            folds_train_accuracy = []\n",
    "            folds_validation_accuracy = []\n",
    "            for x_train, y_train, x_test, y_test in train_set_folds:\n",
    "                w, train_loss = ridge_regression(y_train, x_train, lambda_)\n",
    "                folds_train_accuracy.append(compute_accuracy(predict_labels(w, x_train), y_train))\n",
    "                folds_validation_accuracy.append(compute_accuracy(predict_labels(w, x_test), y_test))\n",
    "            train_accuracy_matrix[jet_num, 0, i, j] = (np.mean(folds_train_accuracy), np.std(folds_train_accuracy))\n",
    "            validation_accuracy_matrix[jet_num, 0, i, j] = (np.mean(folds_validation_accuracy), np.std(folds_validation_accuracy))\n",
    "\n",
    "        train_data_log_svm = preprocessing_pipeline(train_data_split, degree=deg, norm_first=False)\n",
    "        train_set_folds = k_fold_cross_split_data(train_classes_split, train_data_log_svm, k_indices)\n",
    "\n",
    "        \n",
    "        ### Train Log model on fold\n",
    "        for j, lambda_ in enumerate(tqdm(POSSIBLE_LAMBDA_LOG, desc='log loop', leave=False)):\n",
    "            folds_train_accuracy = []\n",
    "            folds_validation_accuracy = []\n",
    "            for x_train, y_train, x_test, y_test in train_set_folds:\n",
    "                initial_w = np.zeros((x_train.shape[1],))\n",
    "                try:\n",
    "                    w, train_loss = reg_logistic_regression(y_train, x_train, lambda_, initial_w, 150, 3e-1, 1)\n",
    "                    folds_train_accuracy.append(compute_accuracy(predict_labels(w, x_train), y_train))\n",
    "                    folds_validation_accuracy.append(compute_accuracy(predict_labels(w, x_test), y_test))\n",
    "                except Exception:\n",
    "                    pass\n",
    "            train_accuracy_matrix[jet_num, 1, i, j] = (np.mean(folds_train_accuracy), np.std(folds_train_accuracy))\n",
    "            validation_accuracy_matrix[jet_num, 1, i, j] = (np.mean(folds_validation_accuracy), np.std(folds_validation_accuracy))\n",
    "        \n",
    "        \n",
    "        ### Train svm model on fold\n",
    "        for j, lambda_ in enumerate(tqdm(POSSIBLE_LAMBDA_LOG, desc='svm loop', leave=False)):\n",
    "            folds_train_accuracy = []\n",
    "            folds_validation_accuracy = []\n",
    "            for x_train, y_train, x_test, y_test in train_set_folds:\n",
    "                initial_w = np.zeros((x_train.shape[1],))\n",
    "                try:\n",
    "                    w, train_loss = svm(y_train, x_train, lambda_, initial_w, 500, 1e-5, 1e-1)\n",
    "                    folds_train_accuracy.append(compute_accuracy(predict_labels(w, x_train), y_train))\n",
    "                    folds_validation_accuracy.append(compute_accuracy(predict_labels(w, x_test), y_test))\n",
    "                except Exception:\n",
    "                    pass\n",
    "            train_accuracy_matrix[jet_num, 2, i, j] = (np.mean(folds_train_accuracy), np.std(folds_train_accuracy))\n",
    "            validation_accuracy_matrix[jet_num, 2, i, j] = (np.mean(folds_validation_accuracy), np.std(folds_validation_accuracy))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_best_hyperparameters(error_values, lambdas, degrees):\n",
    "    \"\"\" A function which finds the hyperparameters that give the highest accuracy\n",
    "        \n",
    "    Args:\n",
    "        error_values (np.array) Cross-validation error values of all different \n",
    "        combinations of hyperparameters.\n",
    "        lambdas (np.array): Array of different regularization coefficients to try.\n",
    "        degrees (np.array): Array of different degrees coefficients to try for \n",
    "        feature expansion.\n",
    "\n",
    "    Returns:\n",
    "        (float), (int): Lambda and degree combination that result in lowest error\n",
    "    \"\"\"\n",
    "    best_deg, best_lmbda = np.unravel_index(np.argmax(error_values), error_values.shape)\n",
    "    # Extract the lambda and degree resulting in the highest accuracy.\n",
    "    degree_best = degrees[best_deg]\n",
    "    lambda_best = lambdas[best_lmbda]\n",
    "    return lambda_best, degree_best"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ToDo : save train_accuracy_matrix / test_accuracy_matrix\n",
    "\n",
    "#### THIS ABOVE SHOULD BE IN TRAINING.PY\n",
    "\n",
    "#####THIS BELOW SHOULD BE IN RUN.PY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_log = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_hyper = [(11, 2e-1), (10, 2e-1), (12, 2e-1), (12, 6e-2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 59474.5837442635\n",
      "50 34924.1754279905\n",
      "100 34145.61171942162\n",
      "converged at iter : 144\n",
      "Loss: 34043.085 Accuracy : 0.8492688639116031\n",
      "0 47839.02421297877\n",
      "50 32278.223862363735\n",
      "100 31821.801361800313\n",
      "converged at iter : 125\n",
      "Loss: 31781.714 Accuracy : 0.8132157226864748\n",
      "0 30222.982805878484\n",
      "50 17779.232029577157\n",
      "100 17355.100065551153\n",
      "converged at iter : 131\n",
      "Loss: 17300.824 Accuracy : 0.8495206335973322\n",
      "0 14610.258514485595\n",
      "50 10350.443424413483\n",
      "100 9389.609115668256\n",
      "150 8873.373044491407\n",
      "200 8554.4257320503\n",
      "250 8337.70710705939\n",
      "300 8182.904650568386\n",
      "350 8066.056709368944\n",
      "400 7978.275509149935\n",
      "450 7910.783176154313\n",
      "converged at iter : 468\n",
      "Loss: 7890.391 Accuracy : 0.8521476267821693\n"
     ]
    }
   ],
   "source": [
    "for (deg, gamma), train_classes_split, train_data_split in zip(best_hyper[:], train_classes_jet_num_splits[:], train_data_jet_num_splits[:]):\n",
    "    data_split, columns_to_remove, mean, std = preprocessing_pipeline(train_data_split, degree=np.int(deg), cross_term=True, norm_first=False)\n",
    "    initial_w = np.zeros((data_split.shape[1],))\n",
    "    w, loss = reg_logistic_regression(train_classes_split, data_split, 0, initial_w, 500, gamma, 1)\n",
    "    print(f'Loss: {loss:.3f} Accuracy : {compute_accuracy(predict_labels(w, data_split), train_classes_split)}')\n",
    "    # w, loss = reg_logistic_regression(train_classes_split, data_split, 1e-3, initial_w, 1001, 1e-5)\n",
    "    # w, loss = svm(train_classes_split, data_split, 1e-3, initial_w, 1001, 1e-5)#5e-8)\n",
    "    #print(w, loss)\n",
    "    models_log.append((w, loss, columns_to_remove, mean, std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_classes, test_data, test_ids = load_csv_data(\"data/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_classes_jet_num_splits, test_data_jet_num_splits, test_ids_jet_num_splits = \\\n",
    "    split_data_by_categorical_column(test_classes,\n",
    "                                     test_data,\n",
    "                                     test_ids,\n",
    "                                     PRI_JET_NUM_INDEX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(568238, 2)\n"
     ]
    }
   ],
   "source": [
    "results = None\n",
    "for (w, _, col_to_rm, mean, std), (deg, _), test_classes_split, test_data_split, test_ids_split in zip(models_log, best_hyper, test_classes_jet_num_splits, test_data_jet_num_splits, test_ids_jet_num_splits):\n",
    "    data_split, _, _, _ = preprocessing_pipeline(test_data_split, degree=np.int(deg), columns_to_remove=col_to_rm, cross_term=True, norm_first=False, mean=mean, std=std)\n",
    "    pred = predict_labels(w, data_split)\n",
    "    out = np.stack((test_ids_split, pred), axis=-1)\n",
    "    results = out if results is None else np.vstack((results, out))\n",
    "    \n",
    "print(results.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = None\n",
    "for (w, _, col_to_rm, mean, std), (deg, _), test_classes_split, test_data_split, test_ids_split in zip(models_ridge, best_hyper_ridge, test_classes_jet_num_splits, test_data_jet_num_splits, test_ids_jet_num_splits):\n",
    "    data_split, _, _, _ = preprocessing_pipeline(test_data_split, degree=np.int(deg), columns_to_remove=col_to_rm, norm_first=True, mean=mean, std=std)\n",
    "    pred = predict_labels(w, data_split)\n",
    "    out = np.stack((test_ids_split, pred), axis=-1)\n",
    "    results = out if results is None else np.vstack((results, out))\n",
    "    \n",
    "print(results.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from helpers import create_csv_submission\n",
    "\n",
    "create_csv_submission(results[:, 0], results[:, 1], 'results_final_log.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:ada] *",
   "language": "python",
   "name": "conda-env-ada-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
